{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Movie Recommendation with MLlib\n",
    "\n",
    "In this chapter, we will use MLlib to make personalized movie recommendations tailored for you. We will work with 10 million ratings from 72,000 users on 10,000 movies, collected by MovieLens. This dataset is pre-loaded in HDFS. For quick testing of your code, we use a smaller dataset which contains 1 million ratings from 6000 users on 4000 movies.\n",
    "\n",
    "#1. Data set\n",
    "\n",
    "We will use two files from this MovieLens dataset: “ratings.dat” and “movies.dat”. All ratings are contained in the file “ratings.dat” and are in the following format:\n",
    "\n",
    "`UserID::MovieID::Rating::Timestamp`\n",
    "\n",
    "Movie information is in the file “movies.dat” and is in the following format:\n",
    "\n",
    "`MovieID::Title::Genres`\n",
    "\n",
    "#2. Collaborative filtering\n",
    "\n",
    "Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix, in our case, the user-movie rating matrix. MLlib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. In particular, we implement the alternating least squares (ALS) algorithm to learn these latent factors.\n",
    "\n",
    "<a href=\"url\"><img src=\"http://ampcamp.berkeley.edu/5/exercises/img/matrix_factorization.png\" align=\"center\" height=\"300\" width=\"500\" ></a>\n",
    "\n",
    "#3. Create training examples\n",
    "\n",
    "To make recommendation for you, we are going to learn your taste by asking you to rate a few movies. We have selected a small set of movies that have received the most ratings from users in the MovieLens dataset. You can rate those movies by running rateMovies.py (see below, hit 'run' or 'shift-return').\n",
    "\n",
    "When you run the script, you should see prompt similar to the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Please rate the following movie (1-5 (best), or 0 if not seen):\n",
    "Toy Story (1995):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you’re done rating the movies, we save your ratings in personalRatings.txt in the MovieLens format, where a special user id 0 is assigned to you.\n",
    "\n",
    "rateMovies allows you to re-rate the movies if you’d like to see how your ratings affect your recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parentDir = \n",
      "/home/ubuntu/notebooks/spark_course/6-MLlib-Example\n",
      "Looks like you've already rated the movies. Overwrite ratings (y/N)? y\n",
      "Please rate the following movie (1-5 (best), or 0 if not seen): \n",
      "Toy Story (1995): 0\n",
      "Independence Day (a.k.a. ID4) (1996): 5\n",
      "Dances with Wolves (1990): 0\n",
      "Star Wars: Episode VI - Return of the Jedi (1983): 5\n",
      "Mission: Impossible (1996): 0\n",
      "Ace Ventura: Pet Detective (1994): 0\n",
      "Die Hard: With a Vengeance (1995): 0\n",
      "Batman Forever (1995): 0\n",
      "Pretty Woman (1990): 0\n",
      "Men in Black (1997): 5\n",
      "Dumb & Dumber (1994): 0\n"
     ]
    }
   ],
   "source": [
    "%run rateMovies.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Setup\n",
    "\n",
    "The following are the cells you are going to edit, and run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Initiate Spark Context - ONLY first time for each notebook. If you get problems with below, see [Help](/notebooks/spark_course/1-Course-Information-and-Links/If-you-get-problems-initiating-spark-context.ipynb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(appName=\"search\", master=os.environ['MASTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys                                                                                                                         \n",
    "import itertools                                                                                                                   \n",
    "from math import sqrt                                                                                                              \n",
    "from operator import add                                                                                                           \n",
    "from os.path import join, isfile, dirname                                                                                          \n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return long(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "\n",
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "# ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "ratings = sc.textFile(\"/uuData/movies/ratings.dat\").map(parseRating)\n",
    "\n",
    "# movies is an RDD of (movieId, movieTitle)                                                                                    \n",
    "temp = sc.textFile(\"/uuData/movies/movies.dat\")\n",
    "movies = dict(temp.map(parseMovie).collect()) \n",
    "\n",
    "# load personal ratings\n",
    "myRatings = sc.textFile(\"/uuData/movies/personalRatings.txt\")\n",
    "myRatingsRDD = myRatings.map(lambda l: l.split('::')).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. Running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1000209 ratings from 6040 users on 3706 movies.\n"
     ]
    }
   ],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.values().map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. Splitting training data\n",
    "We will use MLlib’s ALS to train a MatrixFactorizationModel, which takes a RDD[Rating] object as input in Scala and RDD[(user, product, rating)] in Python. ALS has training parameters such as rank for matrix factors and regularization constants. To determine a good combination of the training parameters, we split the data into three non-overlapping subsets, named training, test, and validation, based on the last digit of the timestamp, and cache them. We will train multiple models based on the training set, select the best model on the validation set based on RMSE (Root Mean Squared Error), and finally evaluate the best model on the test set. We also add your ratings to the training set to make recommendations for you. We hold the training, validation, and test sets in memory by calling cache because we need to visit them multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 602252, validation: 198919, test: 199049\n"
     ]
    }
   ],
   "source": [
    "# split ratings into train (60%), validation (20%), and test (20%) based on the\n",
    "# last digit of the timestamp, add myRatings to train, and cache them\n",
    "\n",
    "# training, validation, test are all RDDs of (userId, movieId, rating)\n",
    "\n",
    "numPartitions = 4\n",
    "training = ratings.filter(lambda x: x[0] < 6) \\\n",
    "  .values() \\\n",
    "  .union(myRatingsRDD) \\\n",
    "  .repartition(numPartitions) \\\n",
    "  .cache()\n",
    "\n",
    "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8) \\\n",
    "  .values() \\\n",
    "  .repartition(numPartitions) \\\n",
    "  .cache()\n",
    "\n",
    "test = ratings.filter(lambda x: x[0] >= 8).values().cache()\n",
    "\n",
    "numTraining = training.count()\n",
    "numValidation = validation.count()\n",
    "numTest = test.count()\n",
    "\n",
    "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. Training using ALS\n",
    "In this section, we will use ALS.train to train a bunch of models, and select and evaluate the best. Among the training paramters of ALS, the most important ones are rank, lambda (regularization constant), and number of iterations. The train method of ALS we are going to use is defined as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ALS(object):\n",
    "\n",
    "    def train(cls, ratings, rank, iterations=5, lambda_=0.01, blocks=-1):\n",
    "        # ...\n",
    "    return MatrixFactorizationModel(sc, mod)\n",
    "    \n",
    "//new: def train(cls, ratings, rank, iterations=5, lambda_=0.01, blocks=-1, nonnegative=False,                                        \n",
    "              seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we want to try a large number of combinations of them in order to find the best one. Due to time constraint, we will test only 8 combinations resulting from the cross product of 2 different ranks (8 and 12), 2 different lambdas (1.0 and 10.0), and two different numbers of iterations (10 and 20). We use the provided method computeRmse to compute the RMSE on the validation set for each model. The model with the smallest RMSE on the validation set becomes the one selected and its RMSE on the test set is used as the final metric.\n",
    "\n",
    "*Note: let below step finish before going to the next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (validation) = 0.879141 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 0.872579 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\n",
      "RMSE (validation) = 0.879635 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\n",
      "RMSE (validation) = 0.870872 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n",
      "The best model was trained with rank = 12 and lambda = 0.1, and numIter = 20, and its RMSE on the test set is 0.868953.\n"
     ]
    }
   ],
   "source": [
    "# train models and evaluate them on the validation set\n",
    "\n",
    "ranks = [8, 12]\n",
    "lambdas = [0.1, 10.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1\n",
    "\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    model = ALS.train(training, rank, numIter, lmbda)\n",
    "    validationRmse = computeRmse(model, validation, numValidation)\n",
    "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
    "            \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
    "    if (validationRmse < bestValidationRmse):\n",
    "        bestModel = model\n",
    "        bestValidationRmse = validationRmse\n",
    "        bestRank = rank\n",
    "        bestLambda = lmbda\n",
    "        bestNumIter = numIter\n",
    "\n",
    "testRmse = computeRmse(bestModel, test, numTest)\n",
    "    \n",
    "# evaluate the best model on the test set\n",
    "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "    + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model improves the baseline by 21.96%.\n"
     ]
    }
   ],
   "source": [
    "    # compare the best model with a naive baseline that always returns the mean rating\n",
    "    meanRating = training.union(validation).map(lambda x: x[2]).mean()\n",
    "    baselineRmse = sqrt(test.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTest)\n",
    "    improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
    "    print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print \"File %s does not exist.\" % ratingsFile\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print \"No ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load personal ratings\n",
    "myRatings = loadRatings(\"personalRatings.txt\")\n",
    "myRatingsRDD = sc.parallelize(myRatings, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended for you:\n",
      " 1: Anatomy (Anatomie) (2000)\n",
      " 2: Julien Donkey-Boy (1999)\n",
      " 3: Across the Sea of Time (1995)\n",
      " 4: Welcome to Woop-Woop (1997)\n",
      " 5: Wisdom (1986)\n",
      " 6: Love Serenade (1996)\n",
      " 7: Steal Big, Steal Little (1995)\n",
      " 8: Jakob the Liar (1999)\n",
      " 9: If Lucy Fell (1996)\n",
      "10: Mad Dog Time (1996)\n",
      "11: Isn't She Great? (2000)\n",
      "12: Committed (2000)\n",
      "13: Zachariah (1971)\n",
      "14: In the Mouth of Madness (1995)\n",
      "15: Fall (1997)\n",
      "16: Clean Slate (Coup de Torchon) (1981)\n",
      "17: Sandpiper, The (1965)\n",
      "18: Mr. Jones (1993)\n",
      "19: Postman, The (1997)\n",
      "20: I Confess (1953)\n",
      "21: Leading Man, The (1996)\n",
      "22: Dune (1984)\n",
      "23: Bandits (1997)\n",
      "24: Shattered Image (1998)\n",
      "25: Window to Paris (1994)\n",
      "26: Star Trek V: The Final Frontier (1989)\n",
      "27: Down to You (2000)\n",
      "28: Chill Factor (1999)\n",
      "29: For Love of the Game (1999)\n",
      "30: Star Wars: Episode I - The Phantom Menace (1999)\n",
      "31: Hard Core Logo (1996)\n",
      "32: Belly (1998)\n",
      "33: Message to Love: The Isle of Wight Festival (1996)\n",
      "34: Marnie (1964)\n",
      "35: Goya in Bordeaux (Goya en Bodeos) (1999)\n",
      "36: Grandfather, The (El Abuelo) (1998)\n",
      "37: Anna Karenina (1997)\n",
      "38: Star Trek: The Motion Picture (1979)\n",
      "39: Rules of Engagement (2000)\n",
      "40: Careful (1992)\n",
      "41: Tall Tale (1994)\n",
      "42: Mission to Mars (2000)\n",
      "43: Conspiracy Theory (1997)\n",
      "44: Prophecy II, The (1998)\n",
      "45: Patriot, The (2000)\n",
      "46: Mummy's Tomb, The (1942)\n",
      "47: Star Trek: Insurrection (1998)\n",
      "48: Stargate (1994)\n",
      "49: March of the Wooden Soldiers (a.k.a. Laurel & Hardy in Toyland) (1934)\n",
      "50: Guantanamera (1994)\n"
     ]
    }
   ],
   "source": [
    " # make personalized recommendations\n",
    "\n",
    "myRatedMovieIds = set([x[1] for x in myRatings])\n",
    "candidates = sc.parallelize([m for m in movies if m not in myRatedMovieIds])\n",
    "predictions = bestModel.predictAll(candidates.map(lambda x: (0, x))).collect()\n",
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:50]\n",
    "\n",
    "print \"Movies recommended for you:\"\n",
    "for i in xrange(len(recommendations)):\n",
    "    print (\"%2d: %s\" % (i + 1, movies[recommendations[i][1]])).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise: try above (from the beginning) and see if the recommendation can be changed (put different scores in your rating). What is the limitation with above? What is needed to make it (much) better? \n",
    "\n",
    "### Extra: make a copy of this notebook and change it to simplify rerunning the analysis (move away the parts that you only want to do once). Use this trying to get some reasonable results out of this (small data set): can you e.g. get the recommender to recommend scifi movies?\n",
    "\n",
    "### For the interested student: see https://www.kaggle.com/, and http://en.wikipedia.org/wiki/Netflix_Prize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Material based on AMPCamp and Databricks training material provided online under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
